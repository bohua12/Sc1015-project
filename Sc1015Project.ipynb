{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sc1015Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "_ZfTu0ZTjxe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Goals\n",
        "\n",
        "> Find the main drivers of HDB resale prices\n",
        "\n",
        "> Using dataset from data.gov.sg and also amenities close to a particular area\n",
        "\n",
        "> Random Forest Model for prediction"
      ],
      "metadata": {
        "id": "yFB22kzktZEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading of Data\n",
        "\n",
        "> NumPy : Library for Numeric Computations in Python  \n",
        "> Pandas : Library for Data Acquisition and Preparation  \n",
        "> Matplotlib : Low-level library for Data Visualization  \n",
        "> Seaborn : Higher-level library for Data Visualization"
      ],
      "metadata": {
        "id": "f2NF-u_st-J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt0\n",
        "import seaborn as sb\n",
        "import os\n",
        "sb.set()\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "TutP_0DouND0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpDx9aIPM01-",
        "outputId": "0cc9ebf2-50d1-4bfb-8807-7c0400fb1e68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decided to use the 2015 to current time dataset to clean"
      ],
      "metadata": {
        "id": "b7Bv3nn2tlQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding out the shape and dtype of each column from 2015 dataset using `info` and `shape`"
      ],
      "metadata": {
        "id": "iKisZP-ZsUzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_1990 = pd.read_csv(os.path.join(project_dir, \"content/resale-flat-prices-based-on-approval-date-1990-1999.csv\"))\n",
        "resale_1990.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "BM3f3MfvCVgD",
        "outputId": "7d0bcc49-1775-4646-fc40-e873825f0f08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9bcdeac18fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresale_1990\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content/resale-flat-prices-based-on-approval-date-1990-1999.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresale_1990\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/resale-flat-prices-based-on-approval-date-1990-1999.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resale_2000 = pd.read_csv(os.path.join(project_dir, \"content/resale-flat-prices-based-on-approval-date-2000-feb-2012.csv\"))\n",
        "resale_2000.head()"
      ],
      "metadata": {
        "id": "CEp1OHtQCVax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_2012 = pd.read_csv(os.path.join(project_dir, \"content/resale-flat-prices-based-on-registration-date-from-mar-2012-to-dec-2014.csv\"))\n",
        "resale_2012.head()"
      ],
      "metadata": {
        "id": "is9DXfdNCVXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_first = pd.concat([resale_1990,resale_2000,resale_2012],axis=0,sort=False)\n",
        "resale_first"
      ],
      "metadata": {
        "id": "Pw6Ma3dBCU9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_first.info()"
      ],
      "metadata": {
        "id": "xbzQvuwDDoL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "remaining_list = []\n",
        "for i in resale_first.month:\n",
        "  year = int(i[:4])\n",
        "  remaining = 99 - (year - resale_first.lease_commence_date.iloc[count])\n",
        "  remaining_list.append(remaining)\n",
        "  count+=1\n",
        "\n",
        "resale_first[\"remaining_lease\"] = remaining_list\n",
        "resale_first.head()"
      ],
      "metadata": {
        "id": "NQrjbpAzCU0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_2015 = pd.read_csv(os.path.join(project_dir, \"content/resale-flat-prices-based-on-registration-date-from-jan-2015-to-dec-2016.csv\"))\n",
        "resale_2015.head()"
      ],
      "metadata": {
        "id": "Hok05yW2wAaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_2015.shape"
      ],
      "metadata": {
        "id": "LlwC3G27sHSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_2015.info() # we know that there are no NaN values in any column"
      ],
      "metadata": {
        "id": "_2meQS70shQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding out the shape and dtype of each column from 2017 dataset using `info` and `shape`"
      ],
      "metadata": {
        "id": "-I7sDc5rtGGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_current = pd.read_csv(os.path.join(project_dir,\"content/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\"))\n",
        "resale_current.head()"
      ],
      "metadata": {
        "id": "BHeDeuQls4S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y9zKcMNfmXRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_current.shape"
      ],
      "metadata": {
        "id": "uf6xyfBYtRjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_current.info() #we know there are no NaN values as well in all the columns"
      ],
      "metadata": {
        "id": "IVB7bGwqubw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate both the datasets\n",
        "resale_total = pd.concat([resale_2015,resale_current],axis=0,sort=False)\n",
        "resale_first = resale_first.reindex(columns=resale_total.columns)\n",
        "resale_total = pd.concat([resale_first,resale_total],axis=0,sort=False)\n",
        "resale_total.month = pd.to_datetime(resale_total.month) #to date time\n",
        "\n",
        "resale_total.info()"
      ],
      "metadata": {
        "id": "TsmDs525udqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "*   Change names of the duplicate flat models\n",
        "*   Adjust resale prices according to inflation \n",
        "*   Converting remaining_lease to years\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QJqRE2edw_K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total"
      ],
      "metadata": {
        "id": "s6GmDiawu_yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converting remaining_lease to years"
      ],
      "metadata": {
        "id": "v0kES2bO4omg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(lease):\n",
        "  if type(lease) is str:\n",
        "    length = [int(years) for years in lease.split() if years.isdigit()]\n",
        "    if len(length)>1:\n",
        "      final = length[0] + (length[1])/12\n",
        "    else:\n",
        "      final = length[0]\n",
        "    return final\n",
        "  else:\n",
        "    return lease"
      ],
      "metadata": {
        "id": "BrqcjXB44XV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.remaining_lease = resale_total.remaining_lease.apply(lambda x: convert(x))\n",
        "resale_total"
      ],
      "metadata": {
        "id": "zY4XuTKD6px6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.info()"
      ],
      "metadata": {
        "id": "X4HnB-2k7DLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing duplicate names of flat models"
      ],
      "metadata": {
        "id": "_KTrz_5rH0cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.flat_model.unique()"
      ],
      "metadata": {
        "id": "MmbZq41qILID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.flat_model.value_counts()"
      ],
      "metadata": {
        "id": "gz_buPDBQkQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''rename Improved-Maisonette to Executive Maisonette\n",
        "Premium Maisonette to Executive Maisonette\n",
        "Model A-Maisonette to Maisonette\n",
        "Premium Apartment Loft to Premium Apartment\n",
        "Type S1 and S2 to TypeS1S2'''\n",
        "\n",
        "def change_model(model):\n",
        "  if model == \"Improved-Maisonette\" or model == \"Premium Maisonette\" or model == \"IMPROVED-MAISONETTE\":\n",
        "    rename = \"Executive Maisonette\"\n",
        "  elif model == \"Model A-Maisonette\" or model==\"MODEL A-MAISONETTE\" or model==\"MAISONETTE\":\n",
        "    rename = \"Maisonette\"\n",
        "  elif model == \"Premium Apartment Loft\" or model==\"PREMIUM APARTMENT\":\n",
        "    rename = \"Premium Apartment\"\n",
        "  elif model == \"Type S1\" or model == \"Type S2\":\n",
        "    rename = \"Type S1S2\"\n",
        "  elif model == \"DBSS\":\n",
        "    rename = \"DBSS\"\n",
        "  else:\n",
        "    complete = \"\"\n",
        "    split = model.split()\n",
        "    if len(split) == 1:\n",
        "      return model[0] + model[1:].lower()\n",
        "    else:\n",
        "      for i in split:\n",
        "        complete += (i[0] + i[1:].lower() + \" \")\n",
        "      if complete[-1]==\" \":\n",
        "        complete = complete[0:-1]\n",
        "      return complete\n",
        "  return rename"
      ],
      "metadata": {
        "id": "a_CTKp-TILiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.flat_model = resale_total.flat_model.apply(lambda x:change_model(x))\n",
        "resale_total.flat_model.unique()"
      ],
      "metadata": {
        "id": "e4NBlP5APY5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.flat_model.value_counts()"
      ],
      "metadata": {
        "id": "xYpna_FGQqtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adjusting Resale prices using inflation using CPI"
      ],
      "metadata": {
        "id": "zcRPMrrf7daK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.singstat.gov.sg/find-data/search-by-theme/economy/prices-and-price-indices/latest-data\n",
        "CPI = pd.read_excel(os.path.join(project_dir, 'content/CPI_2022.xlsx'))\n",
        "CPI.head()"
      ],
      "metadata": {
        "id": "og7k_RzD7XHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CPI_rate = pd.DataFrame(CPI.loc[0,'1990 Jan':]).reset_index()\n",
        "CPI_rate.rename(columns={'index':'month',0:'CPI rates'},inplace=True)\n",
        "CPI_rate"
      ],
      "metadata": {
        "id": "qF1CL1QnCUDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CPI_rate.info()"
      ],
      "metadata": {
        "id": "UqqqHA9NXXUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing the month format\n",
        "CPI_rate.month = pd.to_datetime(CPI_rate.month,format='%Y %b')\n",
        "CPI_rate['CPI rates'] = pd.to_numeric(CPI_rate['CPI rates'])\n",
        "CPI_rate.head()"
      ],
      "metadata": {
        "id": "CjFoCU6Dkat9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CPI_rate.info()"
      ],
      "metadata": {
        "id": "DfuFSY6YFcvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging and then calculating adjusted resale price\n",
        "resale_total = resale_total.merge(CPI_rate,on='month',how='left')\n",
        "resale_total"
      ],
      "metadata": {
        "id": "zR8dWzG_BJ2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.info()"
      ],
      "metadata": {
        "id": "SwqNYdMREDna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_price=[]\n",
        "count = 0\n",
        "for i in resale_total['CPI rates']:\n",
        "  if np.isnan(i):\n",
        "    real_price.append(resale_total['resale_price'].iloc[count])\n",
        "  else:\n",
        "    real_price.append((resale_total['resale_price'].iloc[count]/i)*100)\n",
        "  count+=1"
      ],
      "metadata": {
        "id": "fPBZqs9yEtkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total['real_price'] = real_price\n",
        "resale_total"
      ],
      "metadata": {
        "id": "6nHjFJC-FNK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5sAhQob-D6Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "*   Kim's part\n",
        "*   Distance to nearest MRT\n",
        "*   Number of ammementies nearby\n"
      ],
      "metadata": {
        "id": "Je_mpbpXjz2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kim's EDA"
      ],
      "metadata": {
        "id": "BOYzGkI6NEmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.info()"
      ],
      "metadata": {
        "id": "Oqb-SecEiMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis of catagorical variables"
      ],
      "metadata": {
        "id": "WNTLu5CiiSYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data = pd.DataFrame(resale_total[['town', 'flat_type', 'storey_range','flat_model']])\n",
        "resaleCat_data.head()"
      ],
      "metadata": {
        "id": "nM-XJRd4iM3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data = resaleCat_data.astype('category')"
      ],
      "metadata": {
        "id": "tn7svwL7iNDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data.info()"
      ],
      "metadata": {
        "id": "lmWQxfNJi_0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data.describe()"
      ],
      "metadata": {
        "id": "u7Zns7VHi_2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data[\"town\"].nunique() #27 unique towns"
      ],
      "metadata": {
        "id": "aprcVQyai_8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleCat_data[\"town\"].value_counts()"
      ],
      "metadata": {
        "id": "BdJtHJWJi__8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified catplot for counts sorted by the counts\n",
        "sb.catplot(y = 'town', data = resaleCat_data, \n",
        "           kind = \"count\", \n",
        "           height = 8, \n",
        "           order = resaleCat_data['town'].value_counts().index)"
      ],
      "metadata": {
        "id": "YW5EKIpNjAEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified catplot for counts sorted by the counts\n",
        "sb.catplot(y = 'flat_type', data = resaleCat_data, \n",
        "           kind = \"count\", \n",
        "           height = 8, \n",
        "           order = resaleCat_data['flat_type'].value_counts().index)"
      ],
      "metadata": {
        "id": "k9qksCfjjAHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified catplotstorey_rangefor counts sorted by the counts\n",
        "sb.catplot(y = 'storey_range', data = resaleCat_data, \n",
        "           kind = \"count\", \n",
        "           height = 8, \n",
        "           order = resaleCat_data['storey_range'].value_counts().index)"
      ],
      "metadata": {
        "id": "N2szH2p_jAJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified catplotstorey_rangefor counts sorted by the counts\n",
        "sb.catplot(y = 'flat_model', data = resaleCat_data, \n",
        "           kind = \"count\", \n",
        "           height = 8, \n",
        "           order = resaleCat_data['flat_model'].value_counts().index)"
      ],
      "metadata": {
        "id": "Fw-cg9qcjAO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add SalePrice to the dataframe\n",
        "resaleCat_data = pd.concat([resaleCat_data, resale_total[\"resale_price\"]], axis = 1).reindex(resaleCat_data.index)\n",
        "resaleCat_data.head()"
      ],
      "metadata": {
        "id": "rkRWX1ntjATV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # we only need pyplot\n",
        "sb.set() # set the default Seaborn style for graphics"
      ],
      "metadata": {
        "id": "i459g5bHjLc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(16, 8))\n",
        "sb.boxplot(x = 'town', y = 'resale_price', data = resaleCat_data,order = resaleCat_data.groupby('town')['resale_price'].median().sort_values('town').index)\n",
        "# Tilt the x-axis labels for better readability\n",
        "plt.xticks(rotation=45);"
      ],
      "metadata": {
        "id": "jfubUUc_jLfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(16, 8))\n",
        "sb.boxplot(x = 'flat_type', y = 'resale_price', data = resaleCat_data, \n",
        "           order = resaleCat_data.groupby('flat_type')['resale_price'].median().sort_values().index)\n",
        "# Tilt the x-axis labels for better readability\n",
        "plt.xticks(rotation=45);"
      ],
      "metadata": {
        "id": "6UhDXdrujLj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(16, 8))\n",
        "sb.boxplot(x = 'storey_range', y = 'resale_price', data = resaleCat_data, \n",
        "           order = resaleCat_data.groupby('storey_range')['resale_price'].median().sort_values().index)\n",
        "# Tilt the x-axis labels for better readability\n",
        "plt.xticks(rotation=45);"
      ],
      "metadata": {
        "id": "qNPhwYcgjLnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(16, 8))\n",
        "sb.boxplot(x = 'flat_model', y = 'resale_price', data = resaleCat_data, \n",
        "           order = resaleCat_data.groupby('flat_model')['resale_price'].median().sort_values().index)\n",
        "# Tilt the x-axis labels for better readability\n",
        "plt.xticks(rotation=45);"
      ],
      "metadata": {
        "id": "V8gsy8BejLuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see highest variation of resale price is caused by flat model"
      ],
      "metadata": {
        "id": "OiLaVpLBjphQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets analyse numerical variables"
      ],
      "metadata": {
        "id": "It34Y0yjjstY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Numeric Variables"
      ],
      "metadata": {
        "id": "U4lHAZuzjvEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resaleNum_data = pd.DataFrame(resale_total[['floor_area_sqm', 'lease_commence_date', 'remaining_lease','CPI rates']])\n",
        "resaleNum_data.head()"
      ],
      "metadata": {
        "id": "sKWqIRkxjLxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleNum_data.describe()"
      ],
      "metadata": {
        "id": "HusOh6Z9jL31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw the distributions of all variables\n",
        "f, axes = plt.subplots(4, 3, figsize=(18, 20))\n",
        "\n",
        "count = 0\n",
        "for var in resaleNum_data:\n",
        "    sb.boxplot(data = resaleNum_data[var], orient = \"h\", ax = axes[count,0])\n",
        "    sb.histplot(data = resaleNum_data[var], ax = axes[count,1])\n",
        "    sb.violinplot(data = resaleNum_data[var], orient = \"h\", ax = axes[count,2])\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "Jys_4RBmjL5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the quartiles\n",
        "Q1 = resaleNum_data.quantile(0.25)\n",
        "Q3 = resaleNum_data.quantile(0.75)\n",
        "\n",
        "# Rule to identify outliers\n",
        "rule = ((resaleNum_data < (Q1 - 1.5 * (Q3 - Q1))) | (resaleNum_data > (Q3 + 1.5 * (Q3 - Q1))))\n",
        "\n",
        "# Count the number of outliers\n",
        "rule.sum()"
      ],
      "metadata": {
        "id": "4QPPGA-mjL-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaleNum_data.skew()"
      ],
      "metadata": {
        "id": "r7ZDvmazj3rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add resale price to the dataframe\n",
        "resaleNum_data = pd.concat([resaleNum_data, resale_total[\"resale_price\"]], axis = 1).reindex(resaleNum_data.index)\n",
        "\n",
        "# Correlation Matrix\n",
        "print(resaleNum_data.corr())\n",
        "\n",
        "# Heatmap of the Correlation Matrix\n",
        "f = plt.figure(figsize=(12, 12))\n",
        "sb.heatmap(resaleNum_data.corr(), vmin = -1, vmax = 1, linewidths = 1,\n",
        "           annot = True, fmt = \".2f\", annot_kws = {\"size\": 18}, cmap = \"RdBu\")"
      ],
      "metadata": {
        "id": "zNcC4tb2j3yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CPI rates has highest correlation with the resale price and remaining lease has the lowest correlation with the resale price. It is interesting and unexpecting to see the low correlation between resale price and remaining lease as we usually expect a house with a longer lease to have higher value as we can stay in the house longer. On the other hand, the fact that CPI rate having the highest correlation with the resale price, as increasing CPI leads to higher inflation, which would eventually lead to rise in resale prices of the houses. \n"
      ],
      "metadata": {
        "id": "ROTNyCyvj7BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sb.jointplot(data = resaleNum_data, x = \"floor_area_sqm\", y = \"resale_price\", height = 12)"
      ],
      "metadata": {
        "id": "qiEMUAs4j-sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb.jointplot(data = resaleNum_data, x = \"remaining_lease\", y = \"resale_price\", height = 12)"
      ],
      "metadata": {
        "id": "8x_3W9qXj-u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb.jointplot(data = resaleNum_data, x = \"lease_commence_date\", y = \"resale_price\", height = 12)"
      ],
      "metadata": {
        "id": "M18j8elzj-y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb.jointplot(data = resaleNum_data, x = \"CPI rates\", y = \"resale_price\", height = 12)"
      ],
      "metadata": {
        "id": "jCK3tCEaj-4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding distance to nearest MRT"
      ],
      "metadata": {
        "id": "D8KGIcO3NLGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R6b0IYFpkAug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the reliability of our public transport and high cost of owning a car, Singaporeans are rather dependent on MRTs. Thus distance to the nearest MRT station is often one factor that homeowners consider when purchasing a house. We will be using OneMap API to calculate the distance between a flat and the nearest MRT station to analyse this effect"
      ],
      "metadata": {
        "id": "COp6PkYi8YYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total.info()"
      ],
      "metadata": {
        "id": "LId9zI0K819g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resale_total"
      ],
      "metadata": {
        "id": "Y4CNyb4ccXly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Mokt8e5caoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l5vA_ya8caf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "msJDgLWOhoon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function for getting postal code, geo coordinates of addresses\n",
        "\n",
        "def find_postal(lst, filename):\n",
        "    '''With the block number and street name, get the full address of the hdb flat,\n",
        "    including the postal code, geogaphical coordinates (lat/long)'''\n",
        "    \n",
        "    for index,add in enumerate(lst):\n",
        "        # Do not need to change the URL\n",
        "        url= \"https://developers.onemap.sg/commonapi/search?returnGeom=Y&getAddrDetails=Y&pageNum=1&searchVal=\"+ add        \n",
        "        print(index,url)\n",
        "        \n",
        "        # Retrieve information from website\n",
        "        response = requests.get(url)\n",
        "        try:\n",
        "            data = json.loads(response.text) \n",
        "        except ValueError:\n",
        "            print('JSONDecodeError')\n",
        "            pass\n",
        "    \n",
        "        temp_df = pd.DataFrame.from_dict(data[\"results\"])\n",
        "        # The \"add\" is the address that was used to search in the website\n",
        "        temp_df[\"address\"] = add\n",
        "        \n",
        "        # Create the file with the first row that is read in \n",
        "        if index == 0:\n",
        "            file = temp_df\n",
        "        else:\n",
        "            file = file.append(temp_df)\n",
        "    file.to_csv(filename + '.csv')\n",
        "\n",
        "    ## Function for getting closest distance of each location from a list of amenities location\n",
        "\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "def find_nearest(house, amenity, radius=2):\n",
        "    \"\"\"\n",
        "    this function finds the nearest locations from the 2nd table from the 1st address\n",
        "    Both are dataframes with a specific format:\n",
        "        1st column: any string column ie addresses taken from the \"find_postal_address.py\"\n",
        "        2nd column: latitude (float)\n",
        "        3rd column: longitude (float)\n",
        "    Column name doesn't matter.\n",
        "    It also finds the number of amenities within the given radius (default=2)\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    # first column must be address\n",
        "    for index,flat in enumerate(house.iloc[:,0]):\n",
        "        \n",
        "        # 2nd column must be latitude, 3rd column must be longitude\n",
        "        flat_loc = (house.iloc[index,1],house.iloc[index,2])\n",
        "        flat_amenity = ['','',100,0]\n",
        "        for ind, eachloc in enumerate(amenity.iloc[:,0]):\n",
        "            amenity_loc = (amenity.iloc[ind,1],amenity.iloc[ind,2])\n",
        "            distance = geodesic(flat_loc,amenity_loc)\n",
        "            distance = float(str(distance)[:-3]) # convert to float\n",
        "\n",
        "            if distance <= radius:   # compute number of amenities in 2km radius\n",
        "                flat_amenity[3] += 1\n",
        "\n",
        "            if distance < flat_amenity[2]: # find nearest amenity\n",
        "                flat_amenity[0] = flat\n",
        "                flat_amenity[1] = eachloc\n",
        "                flat_amenity[2] = distance\n",
        "\n",
        "        results[flat] = flat_amenity\n",
        "    return results\n",
        "\n",
        "def dist_from_location(house, location):\n",
        "    \"\"\"\n",
        "    this function finds the distance of a location from the 1st address\n",
        "    First is a dataframe with a specific format:\n",
        "        1st column: any string column ie addresses taken from the \"find_postal_address.py\"\n",
        "        2nd column: latitude (float)\n",
        "        3rd column: longitude (float)\n",
        "    Column name doesn't matter.\n",
        "    Second is tuple with latitude and longitude of location\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    # first column must be address\n",
        "    for index,flat in enumerate(house.iloc[:,0]):\n",
        "        \n",
        "        # 2nd column must be latitude, 3rd column must be longitude\n",
        "        flat_loc = (house.iloc[index,1],house.iloc[index,2])\n",
        "        flat_amenity = ['',100]\n",
        "        distance = geodesic(flat_loc,location)\n",
        "        distance = float(str(distance)[:-3]) # convert to float\n",
        "        flat_amenity[0] = flat\n",
        "        flat_amenity[1] = distance\n",
        "        results[flat] = flat_amenity\n",
        "    return results"
      ],
      "metadata": {
        "id": "Lb1c-I3e65mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m256FmaM760r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}